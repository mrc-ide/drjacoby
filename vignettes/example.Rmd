---
title: "Basic Example"
author: "Bob Verity and Pete Winskill"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basic Example}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, echo = FALSE}
# set random seed
set.seed(1)

# load the drjacoby package
library(drjacoby)
```

The likelihood and prior distributions that go into *drjacoby* can be specified by the user either as R functions or as C++ functions. This vignette demonstrates a basic MCMC implementation using both the R and C++ methods, and compares the two in terms of speed.


## Setup

We need the following elements to run *drjacoby*:

1. Some data
2. Some parameters
3. A likelihood function
4. A prior function

Starting with the data, let's assume that our observations consist of a series of draws from a normal distribution with a given mean (`mu_true`) and standard deviation (`sigma_true`). We can generate some random data to play with:

```{r}
# set random seed
set.seed(1)

# define true parameter values
mu_true <- 3
sigma_true <- 2

# draw example data
data_list <- list(x = rnorm(10, mean = mu_true, sd = sigma_true))
```

Notice that data needs to be defined as a named list. For our example MCMC we will assume that we know the correct distribution of the data (i.e. we know the data is normally distributed), and we know that the mean is no smaller than -10 and no larger than 10, but otherwise the parameters of the distribution are unknown. Parameters within *drjacoby* are defined in dataframe format, where we specify minimum and maximum values of all parameters. We can start with an empty `data.frame()` and then add parameters manually (or programmatically) with the `add_parameter()` function. You can see in the printed `df_params` object there is some additional information coding the transformation type and if the parameter will be inferred.

```{r}
# define parameters dataframe
df_params <- data.frame() |>
  add_parameter(name = "mu", min = -10, max = 10) |>
  add_parameter(name = "sigma", min = 0, max = Inf)

print(df_params)
```

In this example we have one parameter (`mu`) that occupies a finite range [-10, 10], and another parameter (`sigma`) that can take any positive value. *drjacoby* deals with different parameter ranges using reparameterisation, which all occurs internally meaning we don't need to worry about these constraints affecting our inference.

Next, we need a likelihood function. This **must** have the following three input arguments, specified in this order:

1. `params` - a named vector of parameter values
3. `data` - a named list of data
4. `misc` - a named list of miscellaneous values

Finally, the function **must** return a single value for the likelihood **in log space**. These constraints on the format of the likelihood function might seem a bit restrictive, but they are needed in order for *drjacoby* to know how to use the function internally. The issue of taking logs is particularly important, as the MCMC will still run even if we forget to take logs, but the results produced will be nonsense!

![Do not underestimate the importance of taking logs.](https://raw.githubusercontent.com/mrc-ide/drjacoby/master/man/figures/loglady.jpg)


Inside the likelihood function we can extract individual parameter values from the input vector and then use these values to calculate the probability of the data. In our example, the likelihood function is quite simple thanks to the `dnorm()` function which can return the density of the normal distribution already in log space:

```{r}
# define log-likelihood function
r_loglike <- function(params, data, misc) {
  
  # extract parameter values
  mu <- params["mu"]
  sigma <- params["sigma"]
  
  # calculate log-probability of data
  ret <- sum(dnorm(data$x, mean = mu, sd = sigma, log = TRUE))
  
  # return
  return(ret)
}
```

Notice that we don't use the `misc` object at all here, which is perfectly fine. Finally, we need a prior function. This **must** have the `params` and `misc` arguments as above, and it **must** return a single value for the prior probability of those parameters **in log space**. Again, this strict format is required for *drjacoby* to know how to use the prior internally. In our case we will assume a uniform prior on `mu`, and a log-normal prior on `sigma`:

```{r}
# define log-prior function
r_logprior <- function(params, misc) {
  
  # extract parameter values
  mu <- params["mu"]
  sigma <- params["sigma"]
  
  # calculate log-prior
  ret <- dunif(mu, min = -10, max = 10, log = TRUE) +
    dlnorm(sigma, meanlog = 0, sdlog = 1.0, log = TRUE)
  
  # return
  return(ret)
}
```

Be careful to ensure that your prior is defined over the same range as specified in the `df_params` dataframe. For example, here our uniform prior for `mu` ranges from -10 to 10, and our log-normal prior for `sigma` ranges from 0 to infinity.


## Running the MCMC

Once we have all the elements above it is straightforward to run a basic MCMC in *drjacoby*. 

First we initialise our mcmc object using `dj$new()`. We provide this object with the data, parameters and likelihood and prior functions. We can also set the number of chains to run

```{r}
# initialise MCMC
mcmc <- dj$new(
  data = data_list,
  df_params = df_params,
  loglike = r_loglike,
  logprior = r_logprior,
  chains = 5
)
mcmc
```

Once initialised we can use two functions, `mcmc$burn()` and `mcmc$sample()` associated with the mcmc object to run the burn-in and sampling iterations for our mcmc, we set `silent = TRUE` here to avoid printing progress bar output, you can leave it on by default. First let's burn-in the chains:

```{r}
# run burn in
mcmc$burn(iterations = 1000, silent = TRUE)
```

Then we can run the sampling iterations

```{r}
# run sampling
mcmc$sample(iterations = 1000, silent = TRUE)

```

A useful feature is that we can call `mcmc$burn()` and `mcmc$sample()` multiple times if needed, essentially stopping then restarting our mcmc.
In the case where we would like more sampling, we could just call `mcmc$sample(iterations = 1000, silent = TRUE)` again, which would give us a total of 2000 sampling iterations.

We can inspect the mcmc output using the `mcmc$output()` function to retrieve the output dataframe. This gives us the parameter samples and loglikelihood and logprior estimates for each iteration, phase (burn-in or sampling) and chain.

```{r}
output <- mcmc$output()
head(output)
```

We can see that both `mu` and `sigma` changed values throughout the burn-in period, as we would expect, and the loglikelihood generally increased.


## Exploring outputs and checking MCMC performance

Before we can draw any conclusions from our MCMC results there are some basic checks that we should carry out. First, we can examine trace plots of all parameters to see how they are moving. This can be done using the `mcmc$plot_par()` function, shown here for the burn-in phase:

```{r, fig.width=8, fig.height=4}
mcmc$plot_par(par = "mu", phase = "burn")
mcmc$plot_par(par = "sigma", phase = "burn")
```

Notice that for all five chains both `mu` and `sigma` move quickly from their initial values to stable levels at around 3 and 2, respectively. This is a visual indication that the MCMC has burned in for an appropriate number of iterations. We can check this more rigorously by looking at the `mcmc$rhat()` output diagnostic, which gives the value of the [Gelman-Rubin convergence diagnostic](https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/gelman.diag).

```{r}
mcmc$rhat()
```

Values close to 1 indicate that the MCMC has converged (typically the threshold <1.1 is used). This output uses the variance between chains, and therefore is only available when running multiple chains.

By setting `phase = "sample"` we can look at trace plots from the sampling phase only:

```{r, fig.width=8, fig.height=4}
mcmc$plot_par(par = "mu", phase = "sample")
mcmc$plot_par(par = "sigma", phase = "sample")
```

Here we can see that the MCMC continues to move freely after the burn-in phase, and that all chains appear to be exploring the same part of the parameter space. The final plot shows the autocorrelation of the chains, which in this case falls off rapidly with samples being approximately independent at around 10 lags. This is an indication that the MCMC is mixing well. The marginal histogram shows a single clear peak, although this is still a bit rough so we may want to re-run the MCMC with a larger number of sampling iterations to get a smoother result. We can also explore this by looking at the effective sample size (ESS), which can be accessed via the `mcmc$ess()` function:

```{r}
mcmc$ess()
```

We can see that despite running the MCMC for 1000 sampling iterations, the actual number of effectively independent samples accounting for autocorrelation is lower. When doing any calculation that relies on the number of samples we should use the ESS rather than the raw number of sampling iterations. For example if we want to know the standard error of our estimate of `mu` we should do `sd(mu)/sqrt(ESS)`. But just as importantly, when producing any summary of the posterior that does not make direct use of the number of samples - for example when producing posterior histograms - we should *use all posterior draws*, and we should [not thin samples](https://doi.org/10.1111/j.2041-210X.2011.00131.x) to reduce autocorrelation. This is because a histogram produced from all samples is more accurate than one produced from thinned samples, even if the samples are autocorrelated.

The final question is how confident can we be that our MCMC has actually explored the space well? Although the trace plot above looks good, it is possible to get results that look like this from very pathological MCMC runs. This is a more complex problem that is dealt with in [another vignette](https://mrc-ide.github.io/drjacoby/articles/metropolis_coupling.html).


## Using C++ functions

Although *drjacoby* is an R package, under the hood it is running C++ through the fantastic [cpp11](https://cpp11.r-lib.org/) package. When we pass an R likelihood function to `dj$new()`, as in the example above, the code is forced to jump out of C++ into R to evaluate the likelihood before jumping back into C++. This creates a computational overhead that can be avoided by specifying functions directly within C++.

To use C++ a function within *drjacoby* we first write it out as stand-alone file. The example used here can be found inside the *inst/extdata* folder of the package, and reads as follows:

```{r, echo = FALSE, comment = ''}
likelihood_filename <- system.file("extdata", "example_cpp_functions.cpp", package = 'drjacoby', mustWork = TRUE)
cat(readLines(likelihood_filename), sep = '\n')
```

The logic of this function is identical to the R version above, just written in the language of C++. 
With this set up all we need to do is source our C++ file with `cpp11::cpp_source()` then simply pass the functions to `run_mcmc()`.

As before, there are some constraints on what this function must look like. It **must** take the same three input arguments described in the previous section, defined in the following formats:

1. `params` must be an `cpp11::doubles`
3. `data` must be an `cpp11::list`
4. `misc` must be an `cpp11::list`

All parameter values will be coerced to `double` within the code, hence parameters consisting of integer or boolean values should be dealt with as though they are continuous (for example `TRUE = 1.0`, `FALSE = 0.0`). Second, the function **must** return an object of class `double`. As before, the value returned should be the likelihood evaluated in **log space**.

Even though we are working in C++, we still have access to versions of most of R's nice distribution functions through the `Rmath` library. For example, the `Rf_dnorm4()` function can be accessed within C++ using `R::dnorm()`. A list of probability distributions available within cpp11 can be found [here](https://github.com/atks/Rmath/blob/master/Rmath/Rmath.h).

With these two functions in hand we can run the MCMC exactly the same as before, passing in the new functions:

```{r, echo = FALSE, comment = '', warning=FALSE}
cpp11::cpp_source(likelihood_filename)
```

```{r}
# run MCMC
mcmc_cpp <- dj$new(
  data = data_list,
  df_params = df_params,
  loglike = loglike_cpp11,
  logprior = logprior_cpp11,
  chains = 5
)
mcmc_cpp$burn(iterations = 1000, silent = TRUE)
mcmc_cpp$sample(iterations = 1000, silent = TRUE)
```

You should notice that this MCMC runs faster than the previous version that used R functions. On the other hand, writing C++ functions is arguably more error-prone and difficult to debug than simple R functions. Hence, if efficiency is your goal then C++ versions of both the likelihood and prior should be used, whereas if ease of programming is more important then R functions might be a better choice.

We can have a look at the speed of both mcmc runs using the `$timing()` function 

```{r}
mcmc$timing()$iterations_per_second
mcmc_cpp$timing()$iterations_per_second
```

This was a very easy problem, and so required no fancy MCMC tricks. The [next vignette](https://mrc-ide.github.io/drjacoby/articles/metropolis_coupling.html) demonstrates how *drjacoby* can be applied to a more challenging problem.
