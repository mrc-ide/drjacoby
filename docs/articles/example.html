<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Example MCMC Implementation • drjacoby</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Example MCMC Implementation">
<meta property="og:description" content="drjacoby">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">drjacoby</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/installation.html">Installation</a>
    </li>
    <li>
      <a href="../articles/example.html">Example MCMC Implementation</a>
    </li>
    <li>
      <a href="../articles/metropolis_coupling.html">Metropolis Coupling</a>
    </li>
    <li>
      <a href="../articles/parallel.html">Running Parallel Chains</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mrc-ide/drjacoby">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="example_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Example MCMC Implementation</h1>
                        <h4 class="author">Bob Verity and Pete Winskill</h4>
            
            <h4 class="date">2020-09-28</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/mrc-ide/drjacoby/blob/master/vignettes/example.Rmd"><code>vignettes/example.Rmd</code></a></small>
      <div class="hidden name"><code>example.Rmd</code></div>

    </div>

    
    
<p>The likelihood and prior distributions that go into <em>drjacoby</em> can be specified by the user either as R functions or as C++ functions. This vignette demonstrates a basic MCMC implementation using both the R and C++ methods, and compares the two in terms of speed.</p>
<div id="setup" class="section level2">
<h2 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h2>
<p>We need the following elements to run <em>drjacoby</em>:</p>
<ol style="list-style-type: decimal">
<li>some data</li>
<li>some parameters</li>
<li>a likelihood function</li>
<li>a prior function</li>
</ol>
<p>Starting with the data, let’s assume that our observations consist of a series of draws from a normal distribution with a given mean (<code>mu_true</code>) and standard deviation (<code>sigma_true</code>). We can generate some random data to play with:</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="co"># set random seed</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">1</span>)

<span class="co"># define true parameter values</span>
<span class="no">mu_true</span> <span class="kw">&lt;-</span> <span class="fl">3</span>
<span class="no">sigma_true</span> <span class="kw">&lt;-</span> <span class="fl">2</span>

<span class="co"># draw example data</span>
<span class="no">data_list</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">x</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="fl">10</span>, <span class="kw">mean</span> <span class="kw">=</span> <span class="no">mu_true</span>, <span class="kw">sd</span> <span class="kw">=</span> <span class="no">sigma_true</span>))</pre></body></html></div>
<p>For our example MCMC we will assume that we know the correct distribution of the data (i.e. we know the data is normally distributed), and we know that the mean is no smaller than -10 and no larger than 10, but otherwise the parameters of the distribution are unknown. Parameters within <em>drjacoby</em> are defined in dataframe format, where we specify minimum, maximum, and initial values of all parameters:</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="co"># define parameters dataframe</span>
<span class="no">df_params</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw">name</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"mu"</span>, <span class="st">"sigma"</span>),
                        <span class="kw">min</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(-<span class="fl">10</span>, <span class="fl">0</span>),
                        <span class="kw">max</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">10</span>, <span class="fl">Inf</span>),
                        <span class="kw">init</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">9</span>, <span class="fl">10</span>))

<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span>(<span class="no">df_params</span>)
<span class="co">#&gt;    name min max init</span>
<span class="co">#&gt; 1    mu -10  10    9</span>
<span class="co">#&gt; 2 sigma   0 Inf   10</span></pre></body></html></div>
<p>In this example we have one parameter (<code>mu</code>) that occupies a finite range [-10, 10], and another parameter (<code>sigma</code>) that can take any positive value. <em>drjacoby</em> deals with different parameter ranges using reparameterisation, which all occurs internally meaning we don’t need to worry about these constraints affecting our inference.</p>
<p>Next, we need a likelihood function. This <strong>must</strong> have exactly two input arguments: 1) a vector of parameters, 2) a vector of data, and these <strong>must</strong> be input <strong>in that order</strong>. It also <strong>must</strong> return a single value for the likelihood <strong>in log space</strong>. These constraints on the format of the likelihood function might seem a bit restrictive, but they are needed in order for <em>drjacoby</em> to know how to use the function internally. The issue of taking logs is particularly important, as the MCMC will still run even if we forget to take logs, but the results produced will be nonsense!</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/mrc-ide/drjacoby/version1.0/R_ignore/images/loglady.jpg" alt=""><p class="caption">Do not underestimate the importance of taking logs.</p>
</div>
<p>Inside the likelihood function we can extract individual parameter values from the input vector, and then use these values to calculate the probability of the data. In our example, the likelihood function is quite simple thanks to the <code><a href="https://rdrr.io/r/stats/Normal.html">dnorm()</a></code> function which can return the density of the normal distribution already in log space:</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="co"># define log-likelihood function</span>
<span class="no">r_loglike</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">params</span>, <span class="no">param_i</span>, <span class="no">data</span>, <span class="no">misc</span>) {

  <span class="co"># extract parameter values</span>
  <span class="no">mu</span> <span class="kw">&lt;-</span> <span class="no">params</span>[<span class="st">"mu"</span>]
  <span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="no">params</span>[<span class="st">"sigma"</span>]

  <span class="co"># calculate log-probability of data</span>
  <span class="no">ret</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span>(<span class="no">data</span>$<span class="no">x</span>, <span class="kw">mean</span> <span class="kw">=</span> <span class="no">mu</span>, <span class="kw">sd</span> <span class="kw">=</span> <span class="no">sigma</span>, <span class="kw">log</span> <span class="kw">=</span> <span class="fl">TRUE</span>))

  <span class="co"># return</span>
  <span class="fu"><a href="https://rdrr.io/r/base/function.html">return</a></span>(<span class="no">ret</span>)
}</pre></body></html></div>
<p>Finally, we need a prior function. This <strong>must</strong> take a single vector of parameters as input, and it <strong>must</strong> return a single value for the prior probability of those parameters <strong>in log space</strong>. Again, this strict format is required for <em>drjacoby</em> to know how to use the prior internally. In our case we will assume a uniform prior on <code>mu</code>, and a log-normal prior on <code>sigma</code>:</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="co"># define log-prior function</span>
<span class="no">r_logprior</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">params</span>, <span class="no">param_i</span>, <span class="no">misc</span>) {

  <span class="co"># extract parameter values</span>
  <span class="no">mu</span> <span class="kw">&lt;-</span> <span class="no">params</span>[<span class="st">"mu"</span>]
  <span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="no">params</span>[<span class="st">"sigma"</span>]

  <span class="co"># calculate log-prior</span>
  <span class="no">ret</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span>(<span class="no">mu</span>, <span class="kw">min</span> <span class="kw">=</span> -<span class="fl">10</span>, <span class="kw">max</span> <span class="kw">=</span> <span class="fl">10</span>, <span class="kw">log</span> <span class="kw">=</span> <span class="fl">TRUE</span>) +
    <span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html">dlnorm</a></span>(<span class="no">sigma</span>, <span class="kw">meanlog</span> <span class="kw">=</span> <span class="fl">0</span>, <span class="kw">sdlog</span> <span class="kw">=</span> <span class="fl">1.0</span>, <span class="kw">log</span> <span class="kw">=</span> <span class="fl">TRUE</span>)

  <span class="co"># return</span>
  <span class="fu"><a href="https://rdrr.io/r/base/function.html">return</a></span>(<span class="no">ret</span>)
}</pre></body></html></div>
<p>Be careful to ensure that your prior is defined over the same range as specified in the <code>df_params</code> dataframe. For example, here our uniform prior for <code>mu</code> ranges from -10 to 10, and our log-normal prior for <code>sigma</code> ranges from 0 to infinity.</p>
</div>
<div id="running-the-mcmc" class="section level2">
<h2 class="hasAnchor">
<a href="#running-the-mcmc" class="anchor"></a>Running the MCMC</h2>
<p>Once we have all the elements above it is straightforward to run a basic MCMC in <em>drjacoby</em>. We simply input the four elements listed above, along with the number of burn-in and sampling iterations. By default <em>drjacoby</em> prints progress bars to the console to keep you updated on the progress of the MCMC. When running in R markdown we can use the option <code>pb_markdown = TRUE</code> to print progress bars in a markdown-friendly way, although you will probably want to leave this option turned off when running interactively (simply delete this argument).</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"># run MCMC
mcmc &lt;- run_mcmc(data = data_list,
                 df_params = df_params,
                 loglike = r_loglike,
                 logprior = r_logprior,
                 burnin = 1e3,
                 samples = 1e3,
                 pb_markdown = TRUE)
#&gt; MCMC chain 1
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.7%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.7%
#&gt; 
#&gt; chain completed in 0.187313 seconds
#&gt; MCMC chain 2
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.7%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 24%
#&gt; 
#&gt; chain completed in 0.164318 seconds
#&gt; MCMC chain 3
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.3%
#&gt; 
#&gt; chain completed in 0.155867 seconds
#&gt; MCMC chain 4
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.1%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.6%
#&gt; 
#&gt; chain completed in 0.157244 seconds
#&gt; MCMC chain 5
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.9%
#&gt; 
#&gt; chain completed in 0.159555 seconds</pre></body></html></div>
<p>The output returned by the MCMC function has three parts: 1) an “output” dataframe containing raw posterior draws and other key elements at each iteration of the MCMC, 2) a “diagnostics” object containing useful summaries such as the effective sample size of each parameter, 3) a “parameters” object containing a record of the exact parameters used to run the MCMC. We can take a peek at the first of these outputs:</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">mcmc</span>$<span class="no">output</span>)
<span class="co">#&gt;    chain  rung iteration  stage  logprior loglikelihood       mu     sigma</span>
<span class="co">#&gt; 1 chain1 rung1         1 burnin -8.868205     -33.96977 9.000000 10.000000</span>
<span class="co">#&gt; 2 chain1 rung1         2 burnin -8.868205     -33.96977 9.000000 10.000000</span>
<span class="co">#&gt; 3 chain1 rung1         3 burnin -7.845730     -29.58273 5.341293  7.220550</span>
<span class="co">#&gt; 4 chain1 rung1         4 burnin -7.845730     -29.55180 5.262133  7.220550</span>
<span class="co">#&gt; 5 chain1 rung1         5 burnin -7.845730     -29.55180 5.262133  7.220550</span>
<span class="co">#&gt; 6 chain1 rung1         6 burnin -7.667840     -29.26141 5.750924  6.797553</span></pre></body></html></div>
</div>
<div id="exploring-outputs-and-checking-mcmc-performance" class="section level2">
<h2 class="hasAnchor">
<a href="#exploring-outputs-and-checking-mcmc-performance" class="anchor"></a>Exploring outputs and checking MCMC performance</h2>
<p>Before we can draw any conclusions from our MCMC results there are some basic checks that we should carry out. First, we can examine trace plots of all parameters to see how they are moving. This can be done using the <code><a href="../reference/plot_par.html">plot_par()</a></code> function, shown here for the burn-in phase:</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="fu"><a href="../reference/plot_par.html">plot_par</a></span>(<span class="no">mcmc</span>, <span class="kw">show</span> <span class="kw">=</span> <span class="st">"mu"</span>, <span class="kw">phase</span> <span class="kw">=</span> <span class="st">"burnin"</span>)</pre></body></html></div>
<p><img src="example_files/figure-html/unnamed-chunk-8-1.png" width="768"></p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="fu"><a href="../reference/plot_par.html">plot_par</a></span>(<span class="no">mcmc</span>, <span class="kw">show</span> <span class="kw">=</span> <span class="st">"sigma"</span>, <span class="kw">phase</span> <span class="kw">=</span> <span class="st">"burnin"</span>)</pre></body></html></div>
<p><img src="example_files/figure-html/unnamed-chunk-8-2.png" width="768"></p>
<p>Notice that for all five chains both <code>mu</code> and <code>sigma</code> move quickly from their initial values to stable levels at around 3 and 2, respectively. This is a visual indication that the MCMC has burned in for an appropriate number of iterations.</p>
<p>By leaving out the <code>phase = "burnin"</code> argument we can look at trace plots from the sampling phase only:</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="fu"><a href="../reference/plot_par.html">plot_par</a></span>(<span class="no">mcmc</span>, <span class="kw">show</span> <span class="kw">=</span> <span class="st">"mu"</span>)</pre></body></html></div>
<p><img src="example_files/figure-html/unnamed-chunk-9-1.png" width="768"></p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="fu"><a href="../reference/plot_par.html">plot_par</a></span>(<span class="no">mcmc</span>, <span class="kw">show</span> <span class="kw">=</span> <span class="st">"sigma"</span>)</pre></body></html></div>
<p><img src="example_files/figure-html/unnamed-chunk-9-2.png" width="768"></p>
<p>Here we can see that the MCMC continues to move freely, and that all chains appear to be exploring the same part of the parameter space. The final plot shows the autocorrelation of the chains, which in this case falls off fairly rapidly with samples being approximately independent at around 5 lags. This is another indication that the MCMC is mixing well. The marginal histogram shows a single clear peak, although this is still a bit rough so we may want to re-run the MCMC with a larger number of sampling iterations to get a smoother result. We can also explore this by looking at the effective sample size (ESS), which is stored within the MCMC diagnostics:</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="co"># TODO - ESS is currently broken, so this line does nothing</span>
<span class="no">mcmc</span>$<span class="no">diagnostics</span>$<span class="no">ess</span>
<span class="co">#&gt; NULL</span></pre></body></html></div>
<p>We can see that despite running the MCMC for 1000 sampling iterations, the actual number of effectively independent samples accounting for autocorrelation is much lower. When doing any calculation that relies on the number of samples, we should use the ESS rather than the raw number of sampling iterations. For example if we want to know the standard error of our estimate of <code>mu</code> we should do <code>sd(mu)/sqrt(ESS)</code>. But just as importantly, when producing any summary of the posterior that does not make direct use of this number - for example when producing posterior histograms - we should <em>use all posterior samples</em>, and we should certainly <a href="https://doi.org/10.1111/j.2041-210X.2011.00131.x">not thin samples</a> to reduce autocorrelation. A histogram produced from all samples is more accurate than one produce from thinned samples, even if the samples are autocorrelated.</p>
<p>The final question is how can we be confident that our MCMC has actually explored the space well? Although the trace plot above looks good, it is possible to get results that look like this from very pathological MCMC runs. This is a more complex problem that is dealt with to some extent in <a href="https://mrc-ide.github.io/drjacoby/articles/metropolis_coupling.html">another vignette</a>.</p>
</div>
<div id="using-c-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#using-c-functions" class="anchor"></a>Using C++ functions</h2>
<p>Although <em>drjacoby</em> is an R package, under the hood it is running C++ through the fantastic <a href="https://cran.r-project.org/web/packages/Rcpp/index.html">Rcpp</a> package. When we pass an R likelihood function to <code><a href="../reference/run_mcmc.html">run_mcmc()</a></code>, as in the example above, the code is forced to jump out of C++ into R to evaluate the likelihood before jumping back into C++. This comes with a computational overhead, which can be avoided by specifying functions directly within C++.</p>
<p>To use C++ functions within <em>drjacoby</em> we simply write them directly within R as character strings. As before, there are some constraints on what this function must look like. First, it <strong>must</strong> take as input a <code>std::vector&lt;double&gt;</code> of parameters <strong>followed by</strong> a <code>std::vector&lt;double&gt;</code> of data. Data <strong>must</strong> be input as doubles, and so data consisting of integer or boolean values should be dealt with as though they are continuous values (for example <code>TRUE = 1.0</code>, <code>FALSE = 0.0</code>). Second, the function <strong>must</strong> return an object of class <code>SEXP</code>. The easiest way to achieve this is to calculate the raw return value as a double, and to use the <code>Rcpp::wrap()</code> function when returning to transform to <code>SEXP</code>. As before, the value returned should be the likelihood evaluated in <strong>log space</strong>.</p>
<p>Even though we are workin in C++, we still have access to most of R’s nice distribution functions through the <code>R::</code> namespace. For example, the <code><a href="https://rdrr.io/r/stats/Normal.html">dnorm()</a></code> function can be accessed within C++ using <code>R::dnorm()</code>. A list of probability distributions available within Rcpp can be found <a href="https://teuder.github.io/rcpp4everyone_en/220_dpqr_functions.html#gamma-distribution">here</a>. The <code>r_loglike()</code> function defined above can be re-written in C++ as follows:</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="co"># define cpp log-likelihood function as character string</span>
<span class="no">cpp_loglike</span> <span class="kw">&lt;-</span> <span class="st">"SEXP loglike(Rcpp::NumericVector params, int param_i, Rcpp::List data, Rcpp::List misc) {
  
  // unpack data
  std::vector&lt;double&gt; x = Rcpp::as&lt; std::vector&lt;double&gt; &gt;(data[\"x\"]);
  
  // unpack parameters
  double mu = params[\"mu\"];
  double sigma = params[\"sigma\"];
  
  // sum log-likelihood over all data
  double ret = 0.0;
  for (unsigned int i = 0; i &lt; x.size(); ++i) {
    ret += R::dnorm(x[i], mu, sigma, true);
  }
  
  // return as SEXP
  return Rcpp::wrap(ret);
}"</span></pre></body></html></div>
<p>Similarly, we can define the prior as a C++ function. This function <strong>must</strong> take as input a <code>std::vector&lt;double&gt;</code> of parameters, and <strong>must</strong> output a single <code>SEXP</code> value representing the prior probability of the parameters in <strong>log space</strong>. The <code>r_logprior()</code> function defined above can be re-written in C++ as follows:</p>
<div class="sourceCode" id="cb13"><html><body><pre class="r"><span class="co"># define cpp logprior function</span>
<span class="no">cpp_logprior</span> <span class="kw">&lt;-</span> <span class="st">"SEXP logprior(Rcpp::NumericVector params, int param_i, Rcpp::List misc) {
  
  // extract parameters
  double sigma = params[\"sigma\"];
  
  // calculate logprior
  double ret = -log(20.0) + R::dlnorm(sigma, 0.0, 1.0, true);
  
  // return as SEXP
  return Rcpp::wrap(ret);
}"</span></pre></body></html></div>
<p>With these two functions defined we can run the MCMC exactly the same as before, passing in the new functions as strings:</p>
<div class="sourceCode" id="cb14"><html><body><pre class="r"># run MCMC
mcmc &lt;- run_mcmc(data = data_list,
                 df_params = df_params,
                 loglike = cpp_loglike,
                 logprior = cpp_logprior,
                 burnin = 1e3,
                 samples = 1e3,
                 pb_markdown = TRUE)
#&gt; MCMC chain 1
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.7%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.3%
#&gt; 
#&gt; chain completed in 0.004661 seconds
#&gt; MCMC chain 2
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.8%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23%
#&gt; 
#&gt; chain completed in 0.007077 seconds
#&gt; MCMC chain 3
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.3%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.1%
#&gt; 
#&gt; chain completed in 0.004842 seconds
#&gt; MCMC chain 4
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.8%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 23.5%
#&gt; 
#&gt; chain completed in 0.004769 seconds
#&gt; MCMC chain 5
#&gt; burn-in
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 22.1%
#&gt; sampling phase
#&gt; 
  |                                                                            
  |======================================================================| 100%
#&gt; acceptance rate: 24.6%
#&gt; 
#&gt; chain completed in 0.005155 seconds</pre></body></html></div>
<p>You should see that this MCMC runs considerably faster than the previous version that used R functions. There is a short delay initially while the strings are compiled into functions, but this only occurs the first time a function is compiled. On the other hand, writing C++ functions in this way is more error prone and difficult to debug mistakes. In summary, if efficiency is your goal then C++ versions of both the likelihood and prior should be used, whereas if ease of programming is more important then R versions of these functions should suffice.</p>
<p>This was a very easy problem, and so required no fancy MCMC tricks. The <a href="https://mrc-ide.github.io/drjacoby/articles/metropolis_coupling.html">next vignette</a> demonstrates how <em>drjacoby</em> can be applied to more challenging problems.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Bob Verity, Pete Winskill.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
